orensam
200170694

=== Image Processing - Ex2 ===

--- Submitted Files ---

DFT.m                   - Performs a 1D DFT of a given row vector.
IDFT.m                  - Performs a 1D inverse DFT of a given row vector.
DFT2.m                  - Performs a 2D DFT of a given row matrix.
IDFT2.m                 - Performs a 2D inverse DFT of a given row vector.
convDerivative.m        - Deriviates a given image in both axis using convolution.
fourierDerivative.m     - Deriviates a given image in both axis using DFT.
blurInImageSpace.m      - Blurs a given image using convolution with a gaussian kernel.
blurInFourierSpace.m    - Blurs a given image using DFT and pointwise multiplication 
                          with a gaussian kernel.

--- MATLAB Version ---

MATLAB R2014a on university computers.

--- Functionality ---

In this exercise, I've implemented several functionalities, all revolving around 
Fourier Transformation and convolutions:

First, we have DFT, IDFT, DFT2 and IDFT2.
These functions perform 1D/2D FT/inverse FT.
To perform the 1D DFT/IDFT, I create the Vandermonde DFT matrix using a simple meshgrid.
In the case of IDFT, I take its conjugate, which represents the inverse DFT operation.
In both cases, the relevant matrix is applied to the given signal (row vector), and the output
is the resulting Fourier signal.
Both DFT and IDFT are height-general, i.e given a matrix, they apply the FT to the matrix's lines.
Therefore, performing the 2D variants (DFT2/IDFT2) is simple - apply the 1D transformation
to the image, then transpose the result and apply the 1D transformation again.
The result is that a 1D transformation has been applied to both the rows and columns of the image,
i.e a 2D transformation.
The normalization factors are according to the specifications listed in the course forum -
No normalization is done in DFT and DFT2, and a normaliztion of the vector length is done in
IDFT, which results in a normalization of width*height in IDFT2.

Second, we have convDerivative and fourierDerivative.
Both functions perform a deriviation of the image in both axis.
convDerivarive implements the deriviation by convolving the image with [1,0,-1],[1;0;-1].
fourierDerivative implements the deriviation by transforming the image to the fourier space,
and then deriving it as a function.

Finally, we have blurInImageSpace and blurInFourierSpace.
Both functions blur and image using a gaussian kernel.
blurInImageSpace concolves the image with the kernel.
blurInFourierSpace performs DFT on the image and kernel, multiplies them (pointwise),
and returns the IDFT of the result.

--- Answers to Questions ---

Section 2 (Image Derivatives): Why did you get two different magnitude images?

It seems, indeed, that the results are different between the two methods -
Most of the time, the convolution derivative seems 'stronger' - the edges are more prominent,
and more details are shown.

This can be explained in several ways:

a. The Fourier deriviative is only up-to-a-constant, i.e it gives us the 'general idea' of the
derivative, but the actual values of the derivative magnitude might differ. This is a good
conjecture, considering that the Fourier derivative was, as said before, not as prominent
as the convolution derivative.

b. The more 'natural' way to define a convolution would be with the kernels [1,-1] and [1;-1],
and not [1,0,-1] and [1;0;-1] like we did in this implementation. I say that this is more 'natural'
since deriviation, in general, aimes to estimate difference over as small a neighborhood 
as possible, and this means it make more sense to use a kernel of size 2 than a kernel of size 3.
Bottom line - maybe the switch to Fourier space made the deriviation more accurate, and this
accueacy accounts for the differences.

c. The Fourier derivative is defined for continuous functions, whereas the convolution derivative is
more 'natural' in our case, when deriving a discrete image. This might cause out deriviation of
the fourier-transformed image to be inaccurate.

Section 3 (Convolution Theory): What is the difference between the two results?

According to the convolution theorem, a convolution of two signals (in our case, an image and a
gaussian kernel) is equivalent to performing DFT on both matrices, multiplying them pointwise,
and then performing IDFT on the result.
Therefore, the results are identical.

A side note to that equivalence is some small artifacts that are caused by each method:
The convolution blur has to somehow account for 'missing' edge pixels, and does so by
convolving zero values, which results in a thin black frame around the blurred picture.
The Fourier blur can't always allign the kernel with the middle of the image - in cases where
one of the image's dimensions is even. This results in a small (1 pixel) cyclic shift of the
output image compared to the original.
